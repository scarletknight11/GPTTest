{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-17T16:32:43.537466Z",
     "start_time": "2025-06-17T16:32:29.536222Z"
    }
   },
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "chatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")\n",
    "chatbot(\"Hate this.\")\n",
    "print(chatbot)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBlenderbotForConditionalGeneration.\n",
      "\n",
      "Some layers of TFBlenderbotForConditionalGeneration were not initialized from the model checkpoint at facebook/blenderbot-400M-distill and are newly initialized: ['final_logits_bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<transformers.pipelines.text2text_generation.Text2TextGenerationPipeline object at 0x000001C5EE82FD90>\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T16:32:49.656580Z",
     "start_time": "2025-06-17T16:32:48.343444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = pipeline(task=\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "classifier(\"Hate this.\")"
   ],
   "id": "81d1a4582cf188ab",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mRuntimeError\u001B[39m                              Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 3\u001B[39m\n\u001B[32m      1\u001B[39m classifier = pipeline(task=\u001B[33m\"\u001B[39m\u001B[33msentiment-analysis\u001B[39m\u001B[33m\"\u001B[39m, model=\u001B[33m\"\u001B[39m\u001B[33mdistilbert-base-uncased-finetuned-sst-2-english\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m----> \u001B[39m\u001B[32m3\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mHate this.\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\HuggingFaceLLM\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:159\u001B[39m, in \u001B[36mTextClassificationPipeline.__call__\u001B[39m\u001B[34m(self, inputs, **kwargs)\u001B[39m\n\u001B[32m    124\u001B[39m \u001B[38;5;250m\u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    125\u001B[39m \u001B[33;03mClassify the text(s) given as inputs.\u001B[39;00m\n\u001B[32m    126\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m    156\u001B[39m \u001B[33;03m    If `top_k` is used, one such dictionary is returned per label.\u001B[39;00m\n\u001B[32m    157\u001B[39m \u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m    158\u001B[39m inputs = (inputs,)\n\u001B[32m--> \u001B[39m\u001B[32m159\u001B[39m result = \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[34;43m__call__\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    160\u001B[39m \u001B[38;5;66;03m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001B[39;00m\n\u001B[32m    161\u001B[39m _legacy = \u001B[33m\"\u001B[39m\u001B[33mtop_k\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m kwargs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\HuggingFaceLLM\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1431\u001B[39m, in \u001B[36mPipeline.__call__\u001B[39m\u001B[34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001B[39m\n\u001B[32m   1423\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mnext\u001B[39m(\n\u001B[32m   1424\u001B[39m         \u001B[38;5;28miter\u001B[39m(\n\u001B[32m   1425\u001B[39m             \u001B[38;5;28mself\u001B[39m.get_iterator(\n\u001B[32m   (...)\u001B[39m\u001B[32m   1428\u001B[39m         )\n\u001B[32m   1429\u001B[39m     )\n\u001B[32m   1430\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1431\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrun_single\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpreprocess_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforward_params\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\HuggingFaceLLM\\.venv\\Lib\\site-packages\\transformers\\pipelines\\base.py:1439\u001B[39m, in \u001B[36mPipeline.run_single\u001B[39m\u001B[34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001B[39m\n\u001B[32m   1437\u001B[39m model_inputs = \u001B[38;5;28mself\u001B[39m.preprocess(inputs, **preprocess_params)\n\u001B[32m   1438\u001B[39m model_outputs = \u001B[38;5;28mself\u001B[39m.forward(model_inputs, **forward_params)\n\u001B[32m-> \u001B[39m\u001B[32m1439\u001B[39m outputs = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mpostprocess\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mpostprocess_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1440\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m outputs\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\HuggingFaceLLM\\.venv\\Lib\\site-packages\\transformers\\pipelines\\text_classification.py:213\u001B[39m, in \u001B[36mTextClassificationPipeline.postprocess\u001B[39m\u001B[34m(self, model_outputs, function_to_apply, top_k, _legacy)\u001B[39m\n\u001B[32m    209\u001B[39m outputs = model_outputs[\u001B[33m\"\u001B[39m\u001B[33mlogits\u001B[39m\u001B[33m\"\u001B[39m][\u001B[32m0\u001B[39m]\n\u001B[32m    211\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.framework == \u001B[33m\"\u001B[39m\u001B[33mpt\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    212\u001B[39m     \u001B[38;5;66;03m# To enable using fp16 and bf16\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m213\u001B[39m     outputs = \u001B[43moutputs\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfloat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnumpy\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    214\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    215\u001B[39m     outputs = outputs.numpy()\n",
      "\u001B[31mRuntimeError\u001B[39m: Numpy is not available"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:28:26.124503Z",
     "start_time": "2025-06-05T20:28:26.061893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# we can also pass in a list to classifier\n",
    "text_list = [\"This is great\", \\\n",
    "             \"Thanks for nothing\", \\\n",
    "             \"You've got to work on your face\", \\\n",
    "             \"You're beatiful, never change!\"]\n",
    "\n",
    "classifier(text_list)"
   ],
   "id": "5bb5a5f3529d8740",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998785257339478},\n",
       " {'label': 'POSITIVE', 'score': 0.9680058360099792},\n",
       " {'label': 'NEGATIVE', 'score': 0.877612292766571},\n",
       " {'label': 'NEGATIVE', 'score': 0.7574953436851501}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:29:42.046356Z",
     "start_time": "2025-06-05T20:29:29.665129Z"
    }
   },
   "cell_type": "code",
   "source": "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
   "id": "7d0d0eaecdb882e7",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "config.json:   0%|          | 0.00/1.92k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "73e21988240943d791239942d99d5c59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e622748a7deb484b95dbfdb9bce84dc5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2ae514b0029c4cfd85dfbe480c74f3ad"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0d9d1c9b802e48c7b93939f93bccc449"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2397de64ef354a99b1dcae5cbf309693"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e85c7cc481c14da288289a50a3c30b19"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/280 [00:00<?, ?B/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c0f944356fbd4e5fbef1501817edb5a8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:30:27.750420Z",
     "start_time": "2025-06-05T20:30:27.713093Z"
    }
   },
   "cell_type": "code",
   "source": "classifier(text_list[0])",
   "id": "e8e7713259d2a390",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'label': 'admiration', 'score': 0.9526104927062988},\n",
       "  {'label': 'approval', 'score': 0.03047206625342369},\n",
       "  {'label': 'neutral', 'score': 0.015236238949000835},\n",
       "  {'label': 'excitement', 'score': 0.006063767243176699},\n",
       "  {'label': 'gratitude', 'score': 0.005296194460242987},\n",
       "  {'label': 'joy', 'score': 0.004475208930671215},\n",
       "  {'label': 'curiosity', 'score': 0.004322327207773924},\n",
       "  {'label': 'realization', 'score': 0.004089605528861284},\n",
       "  {'label': 'optimism', 'score': 0.00407722033560276},\n",
       "  {'label': 'disapproval', 'score': 0.004076561890542507},\n",
       "  {'label': 'annoyance', 'score': 0.0035287425853312016},\n",
       "  {'label': 'surprise', 'score': 0.0029730682726949453},\n",
       "  {'label': 'disappointment', 'score': 0.002734640846028924},\n",
       "  {'label': 'love', 'score': 0.0026945793069899082},\n",
       "  {'label': 'amusement', 'score': 0.002486748620867729},\n",
       "  {'label': 'confusion', 'score': 0.0023607409093528986},\n",
       "  {'label': 'pride', 'score': 0.0021013382356613874},\n",
       "  {'label': 'sadness', 'score': 0.001773053896613419},\n",
       "  {'label': 'anger', 'score': 0.0017196929547935724},\n",
       "  {'label': 'caring', 'score': 0.0013670080807060003},\n",
       "  {'label': 'desire', 'score': 0.001047872588969767},\n",
       "  {'label': 'disgust', 'score': 0.0009689946309663355},\n",
       "  {'label': 'fear', 'score': 0.0005249778041616082},\n",
       "  {'label': 'relief', 'score': 0.0004862115893047303},\n",
       "  {'label': 'embarrassment', 'score': 0.00034175056498497725},\n",
       "  {'label': 'grief', 'score': 0.0003389196645002812},\n",
       "  {'label': 'remorse', 'score': 0.0002780951326712966},\n",
       "  {'label': 'nervousness', 'score': 0.00020788467372767627}]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:35:37.218493Z",
     "start_time": "2025-06-05T20:35:34.941357Z"
    }
   },
   "cell_type": "code",
   "source": "chatbot = pipeline(model=\"facebook/blenderbot-400M-distill\")\n",
   "id": "4104acac7c878b63",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T20:54:26.999319Z",
     "start_time": "2025-06-05T20:54:26.965229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers.pipelines.conversational import Conversation\n",
    "\n",
    "conversation = Conversation(\"Hi I'm Sanjit, how are you?\")\n",
    "conversation = chatbot(conversation)\n",
    "print(conversation)\n"
   ],
   "id": "41e31cf162f041be",
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'Conversation' from 'transformers' (C:\\Users\\sanji\\PycharmProjects\\HuggingFaceLLM\\.venv\\Lib\\site-packages\\transformers\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[27]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mtransformers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Conversation\n\u001B[32m      3\u001B[39m conversation = Conversation(\u001B[33m\"\u001B[39m\u001B[33mHi I\u001B[39m\u001B[33m'\u001B[39m\u001B[33mm Sanjit, how are you?\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m      4\u001B[39m conversation = chatbot(conversation)\n",
      "\u001B[31mImportError\u001B[39m: cannot import name 'Conversation' from 'transformers' (C:\\Users\\sanji\\PycharmProjects\\HuggingFaceLLM\\.venv\\Lib\\site-packages\\transformers\\__init__.py)"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "23e3df16d19d6d98"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
